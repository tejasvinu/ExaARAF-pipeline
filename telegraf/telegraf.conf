[global_tags]
  pipeline = "exaaraf"

[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  hostname = ""
  omit_hostname = false

[[inputs.kafka_consumer]]
  ## Kafka brokers.
  brokers = ["kafka-1:19092", "kafka-2:19092", "kafka-3:19092"]
  
  ## Topics to consume.
  topics = ["ipmi_metrics", "node_metrics", "dcgm_metrics", "slurm_metrics"]
  
  ## Consumer group
  consumer_group = "telegraf_metrics_consumers"
  
  ## Data format
  data_format = "json_v2"
  
  [[inputs.kafka_consumer.json_v2]]
    measurement_name = "{{ .name }}"
    timestamp_path = "timestamp"
    timestamp_format = "2006-01-02T15:04:05.999999-07:00"
    
    [[inputs.kafka_consumer.json_v2.field]]
      path = "value"
      type = "float"
    
    [[inputs.kafka_consumer.json_v2.tag]]
      path = "metric_type"
    
    [[inputs.kafka_consumer.json_v2.tag]]
      path = "labels"

[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  urls = ["http://influxdb:8086"]
  
  ## Token for authentication.
  token = "$INFLUXDB_TOKEN"
  
  ## Organization name.
  organization = "$INFLUXDB_ORG"
  
  ## Destination bucket to write into.
  bucket = "$INFLUXDB_BUCKET"
  
  ## Timeout for HTTP messages.
  timeout = "5s"
  
  ## Content-Encoding for write request body, can be set to "gzip" to
  ## compress requests. "identity" means no compression.
  content_encoding = "gzip"
  
  ## Enable service metric collection.
  metric_buffer_limit = 10000