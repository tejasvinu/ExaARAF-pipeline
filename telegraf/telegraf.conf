[global_tags]
  pipeline = "exaaraf"

[agent]
  interval = "10s"
  round_interval = true
  metric_batch_size = 1000
  metric_buffer_limit = 10000
  collection_jitter = "0s"
  flush_interval = "10s"
  flush_jitter = "0s"
  precision = ""
  hostname = ""
  omit_hostname = false

[[inputs.exec]]
  ## Use Kafka console consumer and pipe through our conversion script
  commands = [
    "sh -c 'kafka-console-consumer --bootstrap-server kafka-1:19092,kafka-2:19092,kafka-3:19092 --topic ipmi_metrics,node_metrics,dcgm_metrics,slurm_metrics --group telegraf_metrics_consumers --from-beginning | python3 /etc/telegraf/kafka_to_influx.py'"
  ]
  ## Run the command continuously in "streaming" mode
  data_format = "influx"
  interval = "0"
  timeout = "0"

[[outputs.influxdb_v2]]
  ## The URLs of the InfluxDB cluster nodes.
  urls = ["http://influxdb:8086"]
  
  ## Token for authentication.
  token = "$INFLUXDB_TOKEN"
  
  ## Organization name.
  organization = "$INFLUXDB_ORG"
  
  ## Destination bucket to write into.
  bucket = "$INFLUXDB_BUCKET"
  
  ## Timeout for HTTP messages.
  timeout = "5s"
  
  ## Content-Encoding for write request body, can be set to "gzip" to
  ## compress requests. "identity" means no compression.
  content_encoding = "gzip"
  
  ## Enable service metric collection.
  metric_buffer_limit = 10000